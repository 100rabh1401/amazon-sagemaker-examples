{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packing your TensorFlow model\n",
    "\n",
    "With Amazon SageMaker, you can package your own algorithms that can then be trained and deployed in the SageMaker environment. This notebook guides you through an example using TensorFlow that shows you how to build a container for SageMaker and use it for training.\n",
    "\n",
    "## Permissions\n",
    "\n",
    "Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because it creates new repositories in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this, the new permissions will be available immediately.\n",
    "\n",
    "## The example\n",
    "\n",
    "In this example we show how to package a custom TensorFlow algorithm with a Python example which works with the CIFAR-10 dataset: [CIFAR-10]: http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parts of the algo\n",
    "\n",
    "The `src` directory has all the components you need to package the sample algorithm for Amazon SageMager:\n",
    "\n",
    "    └── src\n",
    "        ├── cifar10.py\n",
    "        └── resnet_model.py\n",
    "\n",
    "Let's discuss each of these in turn:\n",
    "\n",
    "* __`src`__ is the directory which contains the files that are installed in the container.\n",
    "\n",
    "The files that we put in the container are:\n",
    "\n",
    "* __`cifar10.py`__ is the program that implements our training algorithm.\n",
    "* __`resnet_model.py`__ is the program that contains our Resnet model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packing the Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FROM tensorflow/tensorflow:1.11.0-py3\n",
      "\n",
      "RUN apt-get update && apt-get install -y --no-install-recommends git\n",
      "\n",
      "RUN git clone https://github.com/mvsusp/sagemaker-containers.git -b mvs-sagemaker-containers-train-improvements && cd sagemaker-containers && pip install . --quiet --disable-pip-version-check\n",
      "\n",
      "COPY src /opt/ml/code\n",
      "\n",
      "ENV PYTHONPATH /opt/ml/code:$PYTHONPATH\n",
      "ENV SAGEMAKER_TRAINING_MODULE cifar10\n",
      "Sending build context to Docker daemon  23.55kB\n",
      "Step 1/6 : FROM tensorflow/tensorflow:1.11.0-py3\n",
      " ---> 7f147470ab6f\n",
      "Step 2/6 : RUN apt-get update && apt-get install -y --no-install-recommends git\n",
      " ---> Using cache\n",
      " ---> c93c5af50332\n",
      "Step 3/6 : RUN git clone https://github.com/mvsusp/sagemaker-containers.git -b mvs-sagemaker-containers-train-improvements && cd sagemaker-containers && pip install . --quiet --disable-pip-version-check\n",
      " ---> Using cache\n",
      " ---> 3b868bb84114\n",
      "Step 4/6 : COPY src /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 230f3686567a\n",
      "Step 5/6 : ENV PYTHONPATH /opt/ml/code:$PYTHONPATH\n",
      " ---> Using cache\n",
      " ---> 57d18b2afc6c\n",
      "Step 6/6 : ENV SAGEMAKER_TRAINING_MODULE cifar10\n",
      " ---> Using cache\n",
      " ---> ede690fb7079\n",
      "Successfully built ede690fb7079\n",
      "Successfully tagged tensorflow-cifar10-example:latest\n"
     ]
    }
   ],
   "source": [
    "from build_sagemaker_container import build\n",
    "\n",
    "tag = 'tensorflow-cifar10-example:latest'\n",
    "\n",
    "build(base_image='tensorflow/tensorflow:1.11.0-py3', \n",
    "      entrypoint='cifar10.py',\n",
    "      source_dir='src',\n",
    "      tag=tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your algorithm on your local machine\n",
    "\n",
    "When you're packaging you first algorithm to use with Amazon SageMaker, you probably want to test it yourself to make sure it's working correctly. We use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to test both locally and on SageMaker. For more examples with the SageMaker Python SDK, see [Amazon SageMaker Examples](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk). In order to test our algorithm, we need our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the CIFAR-10 dataset\n",
    "Our training algorithm is expecting our training data to be in the file format of [TFRecords](https://www.tensorflow.org/guide/datasets), which is a simple record-oriented binary format that many TensorFlow applications use for training data.\n",
    "Below is a Python script adapted from the [official TensorFlow CIFAR-10 example](https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator), which downloads the CIFAR-10 dataset and converts them into TFRecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "\n",
      "Downloading cifar-10-python.tar.gz\n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Generating /tmp/cifar-10-data/eval.tfrecords\n",
      "Generating /tmp/cifar-10-data/validation.tfrecords\n",
      "Generating /tmp/cifar-10-data/train.tfrecords\n",
      "Removing original files.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "data_dir = '/tmp/cifar-10-data'\n",
    "\n",
    "utils.download_cifar10_tf_records(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval.tfrecords        train.tfrecords       validation.tfrecords\n"
     ]
    }
   ],
   "source": [
    "ls {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-27 16:01:14,582 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2018-10-27 16:01:14,593 sagemaker-containers INFO     Invoking user script\n",
      "\n",
      "Training Env:\n",
      "\n",
      "{\n",
      "    \"module_name\": \"None\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"current_host\": \"3a862cdacd39\",\n",
      "    \"log_level\": 20,\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {}\n",
      "    },\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"hyperparameters\": {\n",
      "        \"train-steps\": 100\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"3a862cdacd39\",\n",
      "        \"hosts\": [\n",
      "            \"3a862cdacd39\"\n",
      "        ]\n",
      "    },\n",
      "    \"framework_module\": \"cifar10\",\n",
      "    \"job_name\": null,\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"hosts\": [\n",
      "        \"3a862cdacd39\"\n",
      "    ],\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    }\n",
      "}\n",
      "\n",
      "Environment variables:\n",
      "\n",
      "SM_NUM_CPUS=2\n",
      "SM_CHANNELS=[\"training\"]\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_RESOURCE_CONFIG={\"current_host\":\"3a862cdacd39\",\"hosts\":[\"3a862cdacd39\"]}\n",
      "SM_HPS={\"train-steps\":100}\n",
      "SM_NUM_GPUS=0\n",
      "SM_FRAMEWORK_MODULE=cifar10\n",
      "SM_HOSTS=[\"3a862cdacd39\"]\n",
      "SM_USER_ARGS=[\"--train-steps\",\"100\"]\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_LOG_LEVEL=20\n",
      "SM_INPUT_DATA_CONFIG={\"training\":{}}\n",
      "SM_MODULE_NAME=None\n",
      "SM_CURRENT_HOST=3a862cdacd39\n",
      "SM_TRAINING_ENV={\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"3a862cdacd39\",\"framework_module\":\"cifar10\",\"hosts\":[\"3a862cdacd39\"],\"hyperparameters\":{\"train-steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{}},\"input_dir\":\"/opt/ml/input\",\"job_name\":null,\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"None\",\"network_interface_name\":\"ethwe\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"resource_config\":{\"current_host\":\"3a862cdacd39\",\"hosts\":[\"3a862cdacd39\"]}}\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_HP_TRAIN-STEPS=100\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_NETWORK_INTERFACE_NAME=ethwe\n",
      "SM_MODULE_DIR=/opt/ml/code\n",
      "\n",
      "Invoking script with the following command:\n",
      "\n",
      "/usr/bin/python3 -m cifar10 --train-steps 100\n",
      "\n",
      "\n",
      "2018-10-27 16:01:49,564 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    }
   ],
   "source": [
    "training_channel = '/opt/ml/input/data/training'\n",
    "\n",
    "!docker run -v {data_dir}:{training_channel} {tag} train --train-steps 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Python SDK Local Training\n",
    "To represent our training, we use the Estimator class, which needs to be configured in five steps. \n",
    "1. IAM role - our AWS execution role\n",
    "2. train_instance_count - number of instances to use for training.\n",
    "3. train_instance_type - type of instance to use for training. For training locally, we specify `local`.\n",
    "4. image_name - our custom TensorFlow Docker image we created.\n",
    "5. hyperparameters - hyperparameters we want to pass.\n",
    "\n",
    "Let's start with setting up our IAM role. We make use of a helper function within the Python SDK. This function throw an exception if run outside of a SageMaker notebook instance, as it gets metadata from the notebook instance. If running outside, you must provide an IAM role with proper access stated above in [Permissions](#Permissions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = 'SageMakerRole'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit\n",
    "\n",
    "Now that the rest of our estimator is configured, we can call `fit()` with the path to our local CIFAR10 dataset prefixed with `file://`. This invokes our TensorFlow container with 'train' and passes in our hyperparameters and other metadata as json files in /opt/ml/input/config within the container.\n",
    "\n",
    "After our training has succeeded, our training algorithm outputs our trained model within the /opt/ml/model directory, which is used to handle predictions.\n",
    "\n",
    "We recommend testing and training your training algorithm locally first, as it provides quicker iterations and better debuggability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tensorflow-cifar10-example-2018-10-27-16-01-50-216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmp0qm14j3w_algo-1-YTELL_1 ... \n",
      "\u001b[1BAttaching to tmp0qm14j3w_algo-1-YTELL_1\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m 2018-10-27 16:01:53,668 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m 2018-10-27 16:01:53,685 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m \n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m \n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"module_name\": \"None\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"current_host\": \"algo-1-YTELL\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"framework_module\": \"cifar10\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m         \"train-steps\": 100\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"network_interface_name\": \"ethwe\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m         \"algo-1-YTELL\"\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"job_name\": null,\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m         \"current_host\": \"algo-1-YTELL\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m             \"algo-1-YTELL\"\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m             \"ContentType\": \"application/octet-stream\"\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m     }\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m \n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m \n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_HOSTS=[\"algo-1-YTELL\"]\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_TRAINING_ENV={\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-YTELL\",\"framework_module\":\"cifar10\",\"hosts\":[\"algo-1-YTELL\"],\"hyperparameters\":{\"train-steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"ContentType\":\"application/octet-stream\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":null,\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"None\",\"network_interface_name\":\"ethwe\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"resource_config\":{\"current_host\":\"algo-1-YTELL\",\"hosts\":[\"algo-1-YTELL\"]}}\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"ContentType\":\"application/octet-stream\"}}\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=ethwe\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_HPS={\"train-steps\":100}\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-YTELL\",\"hosts\":[\"algo-1-YTELL\"]}\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_HP_TRAIN-STEPS=100\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_USER_ARGS=[\"--train-steps\",\"100\"]\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_MODULE_NAME=None\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_FRAMEWORK_MODULE=cifar10\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_CURRENT_HOST=algo-1-YTELL\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m \n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m \n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m /usr/bin/python3 -m cifar10 --train-steps 100\n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m \n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m \n",
      "\u001b[36malgo-1-YTELL_1  |\u001b[0m 2018-10-27 16:02:30,951 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmp0qm14j3w_algo-1-YTELL_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'train-steps': 100}\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name='tensorflow-cifar10-example:latest',\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit('file:///tmp/cifar-10-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training in Amazon SageMaker\n",
    "Once you have your container pushed to ECR, you can use it to train models. Let's do that with the algorithm we made above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training\n",
    "\n",
    "We will use the tools provided by the SageMaker Python SDK to upload the data to a default bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "# S3 prefix\n",
    "prefix = 'DEMO-tensorflow-cifar10'\n",
    "\n",
    "data_location = sagemaker.Session().upload_data(data_dir, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing docker image to ECR repository 369233609183.dkr.ecr.us-west-2.amazonaws.com/tensorflow-cifar10-example:latest\n",
      "\n",
      "Login Succeeded\n",
      "The push refers to repository [369233609183.dkr.ecr.us-west-2.amazonaws.com/tensorflow-cifar10-example]\n",
      "796eec1122b4: Preparing\n",
      "9fd96661976b: Preparing\n",
      "741f5fa65bfc: Preparing\n",
      "788a01b9cb70: Preparing\n",
      "4331257a069e: Preparing\n",
      "a6a13fd7a75f: Preparing\n",
      "9ff6cd787adb: Preparing\n",
      "32e1e1d8a456: Preparing\n",
      "9a0f96301e7d: Preparing\n",
      "fde791900dd4: Preparing\n",
      "fa8678ba5abc: Preparing\n",
      "f157c6afd0c0: Preparing\n",
      "75b79e19929c: Preparing\n",
      "4775b2f378bb: Preparing\n",
      "883eafdbe580: Preparing\n",
      "19d043c86cbc: Preparing\n",
      "8823818c4748: Preparing\n",
      "a6a13fd7a75f: Waiting\n",
      "9ff6cd787adb: Waiting\n",
      "32e1e1d8a456: Waiting\n",
      "9a0f96301e7d: Waiting\n",
      "fde791900dd4: Waiting\n",
      "fa8678ba5abc: Waiting\n",
      "75b79e19929c: Waiting\n",
      "4775b2f378bb: Waiting\n",
      "883eafdbe580: Waiting\n",
      "19d043c86cbc: Waiting\n",
      "8823818c4748: Waiting\n",
      "f157c6afd0c0: Waiting\n",
      "788a01b9cb70: Layer already exists\n",
      "4331257a069e: Layer already exists\n",
      "741f5fa65bfc: Layer already exists\n",
      "796eec1122b4: Layer already exists\n",
      "9fd96661976b: Layer already exists\n",
      "9ff6cd787adb: Layer already exists\n",
      "a6a13fd7a75f: Layer already exists\n",
      "32e1e1d8a456: Layer already exists\n",
      "fde791900dd4: Layer already exists\n",
      "9a0f96301e7d: Layer already exists\n",
      "f157c6afd0c0: Layer already exists\n",
      "fa8678ba5abc: Layer already exists\n",
      "75b79e19929c: Layer already exists\n",
      "4775b2f378bb: Layer already exists\n",
      "883eafdbe580: Layer already exists\n",
      "19d043c86cbc: Layer already exists\n",
      "8823818c4748: Layer already exists\n",
      "latest: digest: sha256:478feaece7f9e5bea07dea5c5ea9b975d0755ecc6266aa4671f53d4a4c599099 size: 3881\n"
     ]
    }
   ],
   "source": [
    "from build_sagemaker_container import push\n",
    "\n",
    "ecr_image_name = push(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tensorflow-cifar10-example-2018-10-27-15-46-52-548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-27 15:46:22 Starting - Starting the training job...\n",
      "Launching requested ML instances......\n",
      "Preparing the instances for training...\n",
      "2018-10-27 15:48:04 Downloading - Downloading input data\n",
      "2018-10-27 15:48:11 Training - Downloading the training image...\n",
      "Training image download completed. Training in progress.\n",
      "\u001b[31m2018-10-27 15:48:43,514 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2018-10-27 15:48:43,523 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"framework_module\": \"cifar10\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"num_cpus\": 4,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"log_level\": 20,\n",
      "    \"hyperparameters\": {\n",
      "        \"train-steps\": 1000\n",
      "    },\n",
      "    \"resource_config\": {\n",
      "        \"network_interface_name\": \"ethwe\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"module_name\": \"None\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"job_name\": \"tensorflow-cifar10-example-2018-10-27-15-46-52-548\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_HP_TRAIN-STEPS=1000\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_HPS={\"train-steps\":1000}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=None\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--train-steps\",\"1000\"]\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"cifar10\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"train-steps\":1000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"tensorflow-cifar10-example-2018-10-27-15-46-52-548\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"None\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}}\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=cifar10\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m cifar10 --train-steps 1000\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m2018-10-27 15:49:38,842 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2018-10-27 15:49:40 Uploading - Uploading generated training model\n",
      "2018-10-27 15:49:45 Completed - Training job completed\n",
      "Billable seconds: 101\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {'train-steps': 1000}\n",
    "\n",
    "instance_type = 'ml.c5.xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name=ecr_image_name,\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit({'training':data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- [How Amazon SageMaker interacts with your Docker container for training](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html)\n",
    "- [How Amazon SageMaker interacts with your Docker container for inference](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html)\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "- [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)\n",
    "- [Dockerfile](https://docs.docker.com/engine/reference/builder/)\n",
    "- [scikit-bring-your-own](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
