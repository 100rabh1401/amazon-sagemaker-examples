{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packing your TensorFlow model\n",
    "\n",
    "With Amazon SageMaker, you can package your own algorithms that can then be trained and deployed in the SageMaker environment. This notebook guides you through an example using TensorFlow that shows you how to build a container for SageMaker and use it for training.\n",
    "\n",
    "## Permissions\n",
    "\n",
    "Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because it creates new repositories in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this, the new permissions will be available immediately.\n",
    "\n",
    "## The example\n",
    "\n",
    "In this example we show how to package a custom TensorFlow algorithm with a Python example which works with the CIFAR-10 dataset: [CIFAR-10]: http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parts of the algo\n",
    "\n",
    "The `src` directory has all the components you need to package the sample algorithm for Amazon SageMager:\n",
    "\n",
    "    └── src\n",
    "        ├── cifar10.py\n",
    "        └── resnet_model.py\n",
    "\n",
    "Let's discuss each of these in turn:\n",
    "\n",
    "* __`src`__ is the directory which contains the files that are installed in the container.\n",
    "\n",
    "The files that we put in the container are:\n",
    "\n",
    "* __`cifar10.py`__ is the program that implements our training algorithm.\n",
    "* __`resnet_model.py`__ is the program that contains our Resnet model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packing the Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FROM tensorflow/tensorflow:1.11.0-py3\n",
      "\n",
      "RUN apt-get update && apt-get install -y --no-install-recommends git\n",
      "\n",
      "RUN git clone https://github.com/mvsusp/sagemaker-containers.git -b mvs-sagemaker-containers-train-improvements && cd sagemaker-containers && pip install . --quiet --disable-pip-version-check\n",
      "\n",
      "COPY src /opt/ml/code\n",
      "\n",
      "ENV PYTHONPATH /opt/ml/code:$PYTHONPATH\n",
      "ENV SAGEMAKER_TRAINING_MODULE cifar10\n",
      "\n",
      "\n",
      "Sending build context to Docker daemon  23.55kB\n",
      "Step 1/6 : FROM tensorflow/tensorflow:1.11.0-py3\n",
      " ---> 7f147470ab6f\n",
      "Step 2/6 : RUN apt-get update && apt-get install -y --no-install-recommends git\n",
      " ---> Using cache\n",
      " ---> c93c5af50332\n",
      "Step 3/6 : RUN git clone https://github.com/mvsusp/sagemaker-containers.git -b mvs-sagemaker-containers-train-improvements && cd sagemaker-containers && pip install . --quiet --disable-pip-version-check\n",
      " ---> Using cache\n",
      " ---> 3b868bb84114\n",
      "Step 4/6 : COPY src /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 230f3686567a\n",
      "Step 5/6 : ENV PYTHONPATH /opt/ml/code:$PYTHONPATH\n",
      " ---> Using cache\n",
      " ---> 57d18b2afc6c\n",
      "Step 6/6 : ENV SAGEMAKER_TRAINING_MODULE cifar10\n",
      " ---> Using cache\n",
      " ---> ede690fb7079\n",
      "Successfully built ede690fb7079\n",
      "Successfully tagged tensorflow-cifar10-example:latest\n"
     ]
    }
   ],
   "source": [
    "from build_sagemaker_container import build\n",
    "\n",
    "tag = 'tensorflow-cifar10-example:latest'\n",
    "\n",
    "build(base_image='tensorflow/tensorflow:1.11.0-py3',\n",
    "      entrypoint='cifar10.py',\n",
    "      source_dir='src',\n",
    "      tag=tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The build command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrypoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_commands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrypoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_commands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Build your algo using from a Docker `base_image`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        base_image (string): Docker image which your algo is based from.\u001b[0m\n",
       "\u001b[0;34m        entrypoint (string): Path (relative) to the Python source file which should be executed\u001b[0m\n",
       "\u001b[0;34m                as the entry point to training. This should be compatible with either Python 2.7 or Python 3.5.\u001b[0m\n",
       "\u001b[0;34m        source_dir (str): Path (absolute or relative) to a directory with any other training\u001b[0m\n",
       "\u001b[0;34m                source code dependencies aside from tne entry point file (default: None). Structure within this\u001b[0m\n",
       "\u001b[0;34m                directory are preserved when training on Amazon SageMaker.\u001b[0m\n",
       "\u001b[0;34m        tag (string): tag name\u001b[0m\n",
       "\u001b[0;34m        build_commands (string): additional instructions to send to the container\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_ecr_login_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_commands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrypoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/src/amazon-sagemaker-examples/sagemaker-builder/packing-a-tensorflow-model/build_sagemaker_container.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your algorithm on your local machine\n",
    "\n",
    "When you're packaging you first algorithm to use with Amazon SageMaker, you probably want to test it yourself to make sure it's working correctly. We use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to test both locally and on SageMaker. For more examples with the SageMaker Python SDK, see [Amazon SageMaker Examples](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk). In order to test our algorithm, we need our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the CIFAR-10 dataset\n",
    "Our training algorithm is expecting our training data to be in the file format of [TFRecords](https://www.tensorflow.org/guide/datasets), which is a simple record-oriented binary format that many TensorFlow applications use for training data.\n",
    "Below is a Python script adapted from the [official TensorFlow CIFAR-10 example](https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator), which downloads the CIFAR-10 dataset and converts them into TFRecords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "\n",
      "Downloading cifar-10-python.tar.gz\n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Generating /tmp/cifar-10-data/eval.tfrecords\n",
      "Generating /tmp/cifar-10-data/train.tfrecords\n",
      "Generating /tmp/cifar-10-data/validation.tfrecords\n",
      "Removing original files.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "data_dir = '/tmp/cifar-10-data'\n",
    "\n",
    "utils.download_cifar10_tf_records(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval.tfrecords        train.tfrecords       validation.tfrecords\n"
     ]
    }
   ],
   "source": [
    "ls {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-27 17:20:32,416 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "2018-10-27 17:20:32,428 sagemaker-containers INFO     Invoking user script\n",
      "\n",
      "Training Env:\n",
      "\n",
      "{\n",
      "    \"job_name\": null,\n",
      "    \"current_host\": \"8954c2624492\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {}\n",
      "    },\n",
      "    \"hyperparameters\": {\n",
      "        \"train-steps\": 100\n",
      "    },\n",
      "    \"hosts\": [\n",
      "        \"8954c2624492\"\n",
      "    ],\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"framework_module\": \"cifar10\",\n",
      "    \"log_level\": 20,\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"module_name\": \"None\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"8954c2624492\",\n",
      "        \"hosts\": [\n",
      "            \"8954c2624492\"\n",
      "        ]\n",
      "    },\n",
      "    \"num_cpus\": 2,\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"num_gpus\": 0\n",
      "}\n",
      "\n",
      "Environment variables:\n",
      "\n",
      "SM_HOSTS=[\"8954c2624492\"]\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_NETWORK_INTERFACE_NAME=ethwe\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_CHANNELS=[\"training\"]\n",
      "SM_LOG_LEVEL=20\n",
      "SM_INPUT_DATA_CONFIG={\"training\":{}}\n",
      "SM_HP_TRAIN-STEPS=100\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CURRENT_HOST=8954c2624492\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_USER_ARGS=[\"--train-steps\",\"100\"]\n",
      "SM_MODULE_DIR=/opt/ml/code\n",
      "SM_MODULE_NAME=None\n",
      "SM_RESOURCE_CONFIG={\"current_host\":\"8954c2624492\",\"hosts\":[\"8954c2624492\"]}\n",
      "SM_FRAMEWORK_MODULE=cifar10\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_HPS={\"train-steps\":100}\n",
      "SM_TRAINING_ENV={\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"8954c2624492\",\"framework_module\":\"cifar10\",\"hosts\":[\"8954c2624492\"],\"hyperparameters\":{\"train-steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{}},\"input_dir\":\"/opt/ml/input\",\"job_name\":null,\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"None\",\"network_interface_name\":\"ethwe\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"resource_config\":{\"current_host\":\"8954c2624492\",\"hosts\":[\"8954c2624492\"]}}\n",
      "SM_NUM_GPUS=0\n",
      "SM_NUM_CPUS=2\n",
      "\n",
      "Invoking script with the following command:\n",
      "\n",
      "/usr/bin/python3 -m cifar10 --train-steps 100\n",
      "\n",
      "\n",
      "2018-10-27 17:20:59,379 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    }
   ],
   "source": [
    "training_channel = '/opt/ml/input/data/training'\n",
    "\n",
    "!docker run -v {data_dir}:{training_channel} {tag} train --train-steps 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Python SDK Local Training\n",
    "To represent our training, we use the Estimator class, which needs to be configured in five steps. \n",
    "1. IAM role - our AWS execution role\n",
    "2. train_instance_count - number of instances to use for training.\n",
    "3. train_instance_type - type of instance to use for training. For training locally, we specify `local`.\n",
    "4. image_name - our custom TensorFlow Docker image we created.\n",
    "5. hyperparameters - hyperparameters we want to pass.\n",
    "\n",
    "Let's start with setting up our IAM role. We make use of a helper function within the Python SDK. This function throw an exception if run outside of a SageMaker notebook instance, as it gets metadata from the notebook instance. If running outside, you must provide an IAM role with proper access stated above in [Permissions](#Permissions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = 'SageMakerRole'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit\n",
    "\n",
    "Now that the rest of our estimator is configured, we can call `fit()` with the path to our local CIFAR10 dataset prefixed with `file://`. This invokes our TensorFlow container with 'train' and passes in our hyperparameters and other metadata as json files in /opt/ml/input/config within the container.\n",
    "\n",
    "After our training has succeeded, our training algorithm outputs our trained model within the /opt/ml/model directory, which is used to handle predictions.\n",
    "\n",
    "We recommend testing and training your training algorithm locally first, as it provides quicker iterations and better debuggability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tensorflow-cifar10-example-2018-10-27-17-21-00-224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpnnll4yej_algo-1-LQDWW_1 ... \n",
      "\u001b[1BAttaching to tmpnnll4yej_algo-1-LQDWW_1\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m 2018-10-27 17:21:03,462 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m 2018-10-27 17:21:03,474 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m \n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m \n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m         \"algo-1-LQDWW\"\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m         \"train-steps\": 100\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"module_name\": \"None\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m         \"current_host\": \"algo-1-LQDWW\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m             \"algo-1-LQDWW\"\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"network_interface_name\": \"ethwe\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m             \"ContentType\": \"application/octet-stream\"\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"framework_module\": \"cifar10\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"job_name\": null,\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"current_host\": \"algo-1-LQDWW\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m     \"num_cpus\": 2\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m \n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m \n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_USER_ARGS=[\"--train-steps\",\"100\"]\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_TRAINING_ENV={\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-LQDWW\",\"framework_module\":\"cifar10\",\"hosts\":[\"algo-1-LQDWW\"],\"hyperparameters\":{\"train-steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"ContentType\":\"application/octet-stream\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":null,\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"None\",\"network_interface_name\":\"ethwe\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"resource_config\":{\"current_host\":\"algo-1-LQDWW\",\"hosts\":[\"algo-1-LQDWW\"]}}\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_HP_TRAIN-STEPS=100\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_FRAMEWORK_MODULE=cifar10\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"ContentType\":\"application/octet-stream\"}}\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_HOSTS=[\"algo-1-LQDWW\"]\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=ethwe\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_MODULE_NAME=None\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_HPS={\"train-steps\":100}\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_CURRENT_HOST=algo-1-LQDWW\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-LQDWW\",\"hosts\":[\"algo-1-LQDWW\"]}\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m \n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m \n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m /usr/bin/python3 -m cifar10 --train-steps 100\n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m \n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m \n",
      "\u001b[36malgo-1-LQDWW_1  |\u001b[0m 2018-10-27 17:21:38,784 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpnnll4yej_algo-1-LQDWW_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'train-steps': 100}\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name='tensorflow-cifar10-example:latest',\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit('file:///tmp/cifar-10-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training in Amazon SageMaker\n",
    "Once you have your container pushed to ECR, you can use it to train models. Let's do that with the algorithm we made above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training\n",
    "\n",
    "We will use the tools provided by the SageMaker Python SDK to upload the data to a default bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "# S3 prefix\n",
    "prefix = 'DEMO-tensorflow-cifar10'\n",
    "\n",
    "data_location = sagemaker.Session().upload_data(data_dir, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Pushing docker image to ECR repository 369233609183.dkr.ecr.us-west-2.amazonaws.com/tensorflow-cifar10-example:latest\n",
      "\n",
      "The push refers to repository [369233609183.dkr.ecr.us-west-2.amazonaws.com/tensorflow-cifar10-example]\n",
      "796eec1122b4: Preparing\n",
      "9fd96661976b: Preparing\n",
      "741f5fa65bfc: Preparing\n",
      "788a01b9cb70: Preparing\n",
      "4331257a069e: Preparing\n",
      "a6a13fd7a75f: Preparing\n",
      "9ff6cd787adb: Preparing\n",
      "32e1e1d8a456: Preparing\n",
      "9a0f96301e7d: Preparing\n",
      "fde791900dd4: Preparing\n",
      "fa8678ba5abc: Preparing\n",
      "f157c6afd0c0: Preparing\n",
      "75b79e19929c: Preparing\n",
      "4775b2f378bb: Preparing\n",
      "883eafdbe580: Preparing\n",
      "19d043c86cbc: Preparing\n",
      "8823818c4748: Preparing\n",
      "fa8678ba5abc: Waiting\n",
      "f157c6afd0c0: Waiting\n",
      "75b79e19929c: Waiting\n",
      "4775b2f378bb: Waiting\n",
      "883eafdbe580: Waiting\n",
      "19d043c86cbc: Waiting\n",
      "8823818c4748: Waiting\n",
      "32e1e1d8a456: Waiting\n",
      "9a0f96301e7d: Waiting\n",
      "fde791900dd4: Waiting\n",
      "9ff6cd787adb: Waiting\n",
      "a6a13fd7a75f: Waiting\n",
      "4331257a069e: Layer already exists\n",
      "796eec1122b4: Layer already exists\n",
      "788a01b9cb70: Layer already exists\n",
      "9fd96661976b: Layer already exists\n",
      "741f5fa65bfc: Layer already exists\n",
      "32e1e1d8a456: Layer already exists\n",
      "a6a13fd7a75f: Layer already exists\n",
      "9ff6cd787adb: Layer already exists\n",
      "9a0f96301e7d: Layer already exists\n",
      "fde791900dd4: Layer already exists\n",
      "fa8678ba5abc: Layer already exists\n",
      "f157c6afd0c0: Layer already exists\n",
      "75b79e19929c: Layer already exists\n",
      "883eafdbe580: Layer already exists\n",
      "4775b2f378bb: Layer already exists\n",
      "19d043c86cbc: Layer already exists\n",
      "8823818c4748: Layer already exists\n",
      "latest: digest: sha256:478feaece7f9e5bea07dea5c5ea9b975d0755ecc6266aa4671f53d4a4c599099 size: 3881\n"
     ]
    }
   ],
   "source": [
    "from build_sagemaker_container import push\n",
    "\n",
    "ecr_image_name = push(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The push command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_region\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_region\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Push the builded tag to ECR.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        tag (string): tag which you named your algo\u001b[0m\n",
       "\u001b[0;34m        aws_account (string): aws account of the ECR repo\u001b[0m\n",
       "\u001b[0;34m        aws_region (string): aws region where the repo is located\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns:\u001b[0m\n",
       "\u001b[0;34m        (string): ECR repo image that was pushed\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maws_account\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maws_account\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_caller_identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Account'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maws_region\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maws_region\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregion_name\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrepository_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mecr_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ecr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maws_region\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_create_ecr_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecr_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepository_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_ecr_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecr_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_account\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mecr_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_push\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maws_account\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maws_region\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mecr_tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/src/amazon-sagemaker-examples/sagemaker-builder/packing-a-tensorflow-model/build_sagemaker_container.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tensorflow-cifar10-example-2018-10-27-17-22-00-357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-27 17:21:30 Starting - Starting the training job...\n",
      "Launching requested ML instances......\n",
      "Preparing the instances for training...\n",
      "2018-10-27 17:23:09 Downloading - Downloading input data\n",
      "2018-10-27 17:23:16 Training - Downloading the training image..\n",
      "\u001b[31m2018-10-27 17:23:44,321 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2018-10-27 17:23:44,331 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        }\n",
      "    },\n",
      "    \"hyperparameters\": {\n",
      "        \"train-steps\": 1000\n",
      "    },\n",
      "    \"log_level\": 20,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"framework_module\": \"cifar10\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"module_name\": \"None\",\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"job_name\": \"tensorflow-cifar10-example-2018-10-27-17-22-00-357\",\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"ethwe\"\n",
      "    }\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--train-steps\",\"1000\"]\u001b[0m\n",
      "\u001b[31mSM_HPS={\"train-steps\":1000}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=cifar10\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"cifar10\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"train-steps\":1000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"tensorflow-cifar10-example-2018-10-27-17-22-00-357\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"None\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}}\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_HP_TRAIN-STEPS=1000\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=None\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m cifar10 --train-steps 1000\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "Training image download completed. Training in progress.\u001b[31m2018-10-27 17:24:40,681 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2018-10-27 17:24:41 Uploading - Uploading generated training model\n",
      "2018-10-27 17:24:46 Completed - Training job completed\n",
      "Billable seconds: 98\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {'train-steps': 1000}\n",
    "\n",
    "instance_type = 'ml.c5.xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name=ecr_image_name,\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit({'training':data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- [How Amazon SageMaker interacts with your Docker container for training](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html)\n",
    "- [How Amazon SageMaker interacts with your Docker container for inference](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html)\n",
    "- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "- [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)\n",
    "- [Dockerfile](https://docs.docker.com/engine/reference/builder/)\n",
    "- [scikit-bring-your-own](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
