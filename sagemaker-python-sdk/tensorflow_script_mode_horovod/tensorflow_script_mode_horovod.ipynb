{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Script Mode - Using Horovod\n",
    "\n",
    "Starting from TensorFlow version 1.12, you can use Horovod for distributed training.\n",
    "\n",
    "For this example, we use [Tensorflow Model ZOO](https://github.com/tensorflow/models) and [TensorFlow Benchmarks repo](https://github.com/tensorflow/benchmarks) to train a VGG16 model with synthetic ImageNet data.\n",
    "\n",
    "## Cloning the repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'benchmarks'...\n",
      "remote: Enumerating objects: 20, done.\u001b[K\n",
      "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 3335 (delta 6), reused 10 (delta 4), pack-reused 3315\u001b[K\n",
      "Receiving objects: 100% (3335/3335), 1.87 MiB | 303.00 KiB/s, done.\n",
      "Resolving deltas: 100% (2327/2327), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/benchmarks.git -b cnn_tf_v1.12_compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 82, done.\u001b[K\n",
      "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
      "remote: Compressing objects: 100% (57/57), done.\u001b[K\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models.git -b v1.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the benchmark script\n",
    "__benchmarks/scripts/tf_cnn_benchmarks.py__ benchmark scripts for multiple models and datasets. You can ```--help``` to check the usage options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: benchmarks/scripts/tf_cnn_benchmarks.py: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!benchmarks/scripts/tf_cnn_benchmarks.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for out specific example, we want to run **tf_cnn_benchmarks.py** with the following arguments:\n",
    "\n",
    "```python\n",
    "benchmarks/scripts/tf_cnn_benchmarks.py --num_batches=1000 --model vgg16  --batch_size 64 \\\n",
    "            --variable_update horovod --horovod_device gpu --use_fp16\n",
    "```\n",
    "### Creating the launcher script\n",
    "Let's create a shell script that calls **tf_cnn_benchmarks.py** with the correct user arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile launcher.sh \n",
    "\n",
    "#!/usr/bin/env bash \n",
    "pip install requests py-cpuinfo\n",
    "        \n",
    "\n",
    "PYTHONPATH=\"/opt/ml/code/models:$PYTHONPATH\" \\\n",
    "python benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \\\n",
    "    --num_batches=1000 --model vgg16  --batch_size 64 \\\n",
    "    --variable_update horovod --horovod_device gpu --use_fp16 \\\n",
    "    --train_dir /opt/ml/model --eval_dir /opt/ml/model --benchmark_log_dir /opt/ml/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script above:\n",
    "- installs the required Python packages **requests** and **cpuinfo**\n",
    "- add **TensorFlow models** repository to the **PYTHONPATH**\n",
    "- invokes the benchmarking script, saving training, evaluation, and benchmark event files under **/opt/ml/model**. This folder will be saved in S3 in the end of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training in SageMaker using multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to train in SageMaker. Let's start by using one instance with multiple GPUs for training.\n",
    "A ml.p3.16xlarge instance has 8 GPUs and is a perfect for this use case. We need to create **distribution**\n",
    "dictionary, with **mpi** enabled, passing the number of processes that will be executed per instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions={'mpi': {'enabled': True, 'processes_per_host': 8}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pass the **launcher.sh** as the script entry point and include both **benchmarks** and **models** \n",
    "as depencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point='launcher.sh'\n",
    "\n",
    "dependencies=[os.path.join(dir_path, 'benchmarks'),\n",
    "                              os.path.join(dir_path, 'models')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the ```TensorFlow``` estimator to start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "                entry_point=entry_point,\n",
    "                role=sagemaker.get_execution_role()\n",
    "                dependencies=dependencies,\n",
    "                train_instance_count=1,\n",
    "                train_instance_type='ml.p3.16xlarge',\n",
    "                framework_version='1.12',\n",
    "                py_version='py3',\n",
    "                script_mode=True,\n",
    "                distributions=distributions\n",
    "            )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `estimator.fit` call bellow starts training without any data channel. The benchmark script generates synthetic ImageNet during training\n",
    "and does not require any data channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring VPC for distributed training\n",
    "Providing a VPC improves the network throught of the training job and considerable increases the performance and stability of Horovod training jobs.\n",
    "\n",
    "This can be done by supplying subnets and security groups to the job launching scripts.\n",
    "We will use the default VPC configuration for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.client('ec2')\n",
    "\n",
    "default_vpc = [vpc['VpcId'] for vpc in ec2.describe_vpcs()['Vpcs'] if vpc[\"IsDefault\"] == True][0]\n",
    "\n",
    "default_security_groups = [group[\"GroupId\"] for group in ec2.describe_security_groups()['SecurityGroups'] \\\n",
    "                   if group[\"GroupName\"] == \"default\" and group[\"VpcId\"] == default_vpc]\n",
    "\n",
    "default_subnets = [subnet[\"SubnetId\"] for subnet in ec2.describe_subnets()[\"Subnets\"] \\\n",
    "                  if subnet[\"VpcId\"] == default_vpc and subnet['DefaultForAz']==True]\n",
    "\n",
    "print(\"Using default VPC:\", default_vpc)\n",
    "print(\"Using default security group:\", default_security_groups)\n",
    "print(\"Using default subnets:\", default_subnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the VPC for distributed training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "                entry_point=entry_point,\n",
    "                role=sagemaker.get_execution_role()\n",
    "                dependencies=dependencies,\n",
    "                train_instance_count=2,\n",
    "                train_instance_type='ml.p3.16xlarge',\n",
    "                framework_version='1.12',\n",
    "                py_version='py3',\n",
    "                script_mode=True,\n",
    "                distributions=distributions,\n",
    "                security_group_ids=security_groups,\n",
    "                subnets=subnets \n",
    "            )  \n",
    "\n",
    "estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
